{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7c74878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\raghava\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\raghava\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: click in c:\\users\\raghava\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\raghava\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\raghava\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\raghava\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\raghava\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\raghava\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\raghava\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\raghava\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7662e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tree import Tree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df00cd",
   "metadata": {},
   "source": [
    "# Download necessary NLTK data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b31577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RAGHAVA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RAGHAVA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\RAGHAVA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\RAGHAVA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\RAGHAVA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56bc19ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a paragraph describing a topic: \n",
      "The forest was alive with the quiet hum of twilight, shadows stretching long and dark across the mossy ground as the sun dipped below the horizon. Ancient trees stood like silent sentinels, their gnarled branches twisting against the dimming sky, creating a cathedral of green and gold. A soft rustle of leaves broke the stillness, betraying the fleeting presence of a deer. It moved with effortless grace, its delicate form barely disturbing the undergrowth before disappearing into the thicket, as if it were a whispered secret shared only with the forest. The air was thick with the earthy scent of damp wood and blooming wildflowers, mingling with the cool bite of the evening, which carried with it the faint promise of rain. High above, the canopy swayed gently in a breeze that barely touched the forest floor, causing scattered rays of dying sunlight to flicker like fleeting embers. Somewhere in the treetops, a solitary bird sang a melody—sweet and melancholic—that echoed faintly through the stillness, as if trying to hold on to the last vestiges of the day. All around, the world seemed to pause, wrapped in the quiet anticipation of nightfall, as the first stars timidly blinked into view through gaps in the leafy ceiling.\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter a paragraph describing a topic: \")\n",
    "paragraph = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef0864",
   "metadata": {},
   "source": [
    "# Step 1: Tokenization and Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0264dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(paragraph)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "clean_tokens = [token.lower() for token in tokens if token.isalnum() and token.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb0b75",
   "metadata": {},
   "source": [
    "# Step 2: Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2abcac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities(pos_tags):\n",
    "    chunked = ne_chunk(pos_tags, binary=False)\n",
    "    named_entities = []\n",
    "    for chunk in chunked:\n",
    "        if isinstance(chunk, Tree):  # If it's a named entity\n",
    "            named_entities.append(\" \".join(c[0] for c in chunk))\n",
    "    return named_entities\n",
    "\n",
    "pos_tags = pos_tag(clean_tokens)\n",
    "named_entities = extract_named_entities(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568323dc",
   "metadata": {},
   "source": [
    "# Step 3: TF-IDF Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f89c1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter paragraph to remove stop words before applying TF-IDF\n",
    "clean_paragraph = \" \".join([word for word in tokens if word.isalnum() and word.lower() not in stop_words])\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([clean_paragraph])\n",
    "tfidf_scores = dict(zip(vectorizer.get_feature_names_out(), tfidf_matrix.toarray()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0fb5a",
   "metadata": {},
   "source": [
    "# Step 4: Word Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54c44e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(clean_tokens)  # Frequency distribution of words\n",
    "\n",
    "\n",
    "# Combine Named Entities with TF-IDF Scores\n",
    "key_phrases = sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "key_phrases = [phrase[0] for phrase in key_phrases if phrase[0].isalpha()]  # Remove any numerical tokens\n",
    "\n",
    "\n",
    "# Combine Named Entities and Keywords\n",
    "top_named_entities = named_entities[:3]  # Top 3 named entities\n",
    "top_keywords = key_phrases[:5]  # Top 5 keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ec101",
   "metadata": {},
   "source": [
    "# Step 5: Dynamically Generate the Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55a7b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the top named entities and important keywords to create a meaningful title\n",
    "title_parts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa351e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if top_named_entities and top_keywords:\n",
    "    generated_title = f\"{top_named_entities[0]}: {', '.join(top_keywords[:3])}\"\n",
    "    \n",
    "elif top_named_entities:\n",
    "    generated_title = f\"{top_named_entities[0]}: Leading Innovation\"\n",
    "    \n",
    "elif top_keywords:\n",
    "    generated_title = f\"{', '.join(top_keywords[:3])}: A Revolutionary Approach\"\n",
    "else:\n",
    "    generated_title = \"Innovative Developments in the Field\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bd1b88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Title:\n",
      "forest, barely, fleeting: A Revolutionary Approach\n",
      "\n",
      "Additional Title Options:\n",
      "No meaningful additional title options could be generated.\n"
     ]
    }
   ],
   "source": [
    "# Display the generated title\n",
    "print(\"\\nGenerated Title:\")\n",
    "print(generated_title)\n",
    "\n",
    "# Provide additional title options by varying combinations of keywords and named entities\n",
    "print(\"\\nAdditional Title Options:\")\n",
    "if top_named_entities and top_keywords:\n",
    "    print(f\"1. {top_named_entities[0]} and {top_keywords[0]}: Shaping the Future\")\n",
    "    print(f\"2. Exploring {', '.join(top_keywords[:3])}\")\n",
    "    print(f\"3. {', '.join(top_named_entities)} and their Vision\")\n",
    "else:\n",
    "    print(\"No meaningful additional title options could be generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654ae8c",
   "metadata": {},
   "source": [
    "# Step 6: Display Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb5e272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Frequency Analysis:\n",
      "forest: 3\n",
      "quiet: 2\n",
      "like: 2\n",
      "stillness: 2\n",
      "fleeting: 2\n",
      "barely: 2\n",
      "alive: 1\n",
      "hum: 1\n",
      "twilight: 1\n",
      "shadows: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nWord Frequency Analysis:\")\n",
    "for word, freq in freq_dist.most_common(10):  # Top 10 most common words\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd354d",
   "metadata": {},
   "source": [
    "# Step 7: Display Key Phrases and Scores for Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9347bdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key Phrases by TF-IDF Scores:\n",
      "forest: 0.2611\n",
      "barely: 0.1741\n",
      "fleeting: 0.1741\n",
      "like: 0.1741\n",
      "quiet: 0.1741\n",
      "stillness: 0.1741\n",
      "across: 0.0870\n",
      "air: 0.0870\n",
      "alive: 0.0870\n",
      "ancient: 0.0870\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKey Phrases by TF-IDF Scores:\")\n",
    "for phrase, score in sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{phrase}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544e6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418755c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
